% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/mdgpd.R
\name{train_mdgpd}
\alias{train_mdgpd}
\title{\[Experimental\] Train a neural estimator for MDGPD}
\usage{
train_mdgpd(
  savepath = "inst/models",
  family = c("mdgpd", "zimdgpd"),
  data_dim = 2L,
  estimator = c("both", "npe", "nbe"),
  K = NULL,
  m = NULL,
  epochs = NULL,
  stopping_epochs = 10,
  quick = FALSE,
  mc.cores = parallel::detectCores() - 1L,
  seed = 1L,
  verbose = TRUE
)
}
\arguments{
\item{savepath}{character; directory to save trained model files (.bson).
Created if it does not exist.}

\item{family}{character; \code{"mdgpd"} (4 parameters) or \code{"zimdgpd"}
(5 parameters, adds pi0).}

\item{data_dim}{integer >= 2; dimension of the multivariate data
(default \code{2L}). A separate neural network is trained for each
data dimension.}

\item{estimator}{character; which estimator(s) to train: \code{"both"}
(default), \code{"npe"}, or \code{"nbe"}.}

\item{K}{integer; number of training parameter sets to sample from the prior.}

\item{m}{integer vector; range of sample sizes for simulated datasets.}

\item{epochs}{integer; maximum number of training epochs.}

\item{stopping_epochs}{integer; early stopping patience.}

\item{quick}{logical; if \code{TRUE}, uses reduced training settings.}

\item{mc.cores}{integer; number of parallel cores for data simulation.}

\item{seed}{integer or \code{NULL}; random seed for reproducibility.}

\item{verbose}{logical; if \code{TRUE}, print progress messages.}
}
\value{
A named list of file paths to saved .bson model files (invisible).
}
\description{
Trains Neural Posterior Estimator (NPE) and/or Neural Bayesian Estimator
(NBE) networks for MDGPD inference. Based on the Aka, Kratz &
Naveau (2025) framework. Requires Julia (>= 1.11) with NeuralEstimators.jl
and Flux.jl installed, plus the R packages \pkg{JuliaConnectoR} and
\pkg{NeuralEstimators}.
}
\details{
This function is \strong{experimental} and its interface may change.

The training procedure:
\enumerate{
  \item Samples parameters from uniform priors:
    \code{sigma ~ U(0.1, 10)}, \code{xi ~ U(0.01, 0.5)},
    \code{lambda ~ U(0.01, 5)}, \code{rho ~ U(0.01, 0.99)},
    and for ZIMDGPD: \code{pi0 ~ U(0.01, 0.9)}.
  \item Simulates \code{data_dim}-dimensional MDGPD data using
    \code{\link{rmdgpd}} or \code{\link{rzimdgpd}}.
  \item Applies variance-stabilizing (signed log) and parameter transforms
    (\code{log} for sigma/xi/lambda, \code{logit} for rho and pi0).
  \item Trains the neural network(s).
  \item Saves trained states as .bson files.
}

Model files are named with a dimension-specific prefix (e.g.,
\code{MDGPD_NPE.bson} for \code{data_dim = 2},
\code{MDGPD_3D_NPE.bson} for \code{data_dim = 3}).
}
\examples{
\dontrun{
# 2D (default)
paths <- train_mdgpd(savepath = tempdir(), family = "mdgpd", quick = TRUE)
# 3D
paths3 <- train_mdgpd(savepath = tempdir(), family = "mdgpd",
                       data_dim = 3L, quick = TRUE)
}

}
\references{
Aka, S., Kratz, M., and Naveau, P. (2025). Multivariate discrete
generalized Pareto distributions: theory, simulation, and applications
to dry spells. \emph{arXiv preprint} arXiv:2506.19361.
}
\seealso{
\code{\link{rmdgpd}}, \code{\link{rzimdgpd}}, \code{\link{train_begpd}}
}
